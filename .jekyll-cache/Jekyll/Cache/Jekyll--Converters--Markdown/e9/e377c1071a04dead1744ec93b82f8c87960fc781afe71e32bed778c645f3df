I"]&<h1 id="study-for-voice-and-emotion-detection">Study for Voice and Emotion Detection</h1>

<h2 id="glosary">Glosary</h2>

<ul>
  <li>Digital Signal Processing (DSP) = DSP is the use of digital processing to perform a wide variety of signal processing operations.</li>
  <li>Waveform = A waveform describes a wave by graphing how an air molecule is displaced, over time.</li>
  <li>Pulse-Code Modulation (PCM) = Pulse-code modulation (PCM) is a method used to represent sampled analog signals.</li>
  <li>Frequency = Frequency is the measure of how many times the waveform repeats in a given amount of time.</li>
  <li>Hertz (Hz) = The common unit of measurements for frequency. Hz represents the number the waveform repetitions per second.</li>
  <li>Ampliture = A measure of how much a molecule is displaced from its resting position.</li>
  <li>Sampling = In DSP, sampling is the reduction of continuous-time signal to a discrete-time signal.</li>
  <li>Formant = A formant is a concentration of acoustic energy around a particular frequency in the speech wave.</li>
  <li>Nyquist Theorem = The Nyquist Theorem states that in order to adequately reproduce a signal, it should be periodically sampled at a rate that is 2X the highest frequency you wish to record.</li>
  <li>Windowing = Windowing is the process of taking a small subset of a larger dataset for processing or analysis.</li>
  <li>Spectrogram = A spectrogram is a visual representation of a signal as it varies with time.</li>
  <li>Fourier transform (FT) = FT is a mathematical transform which decomposes a function ( a signal) into its constituent frequencies.</li>
  <li>Short-time Fourier transform (STFT) = STFT is a Fourier-related transform used to determine the sinusoidal frequency and phase content of local sections of a signal as it changes over time.</li>
  <li>Voltage root-mean square (VRMS) = VRMS is defined as square root of the mean of the squares of the values for the one time period of the sine wave.</li>
</ul>

<h2 id="helpful-links">Helpful links</h2>

<ul>
  <li><a href="https://pudding.cool/2018/02/waveforms/">Interactive introduction to waveforms</a></li>
  <li><a href="https://person2.sol.lu.se/SidneyWood/praate/whatform.html">What are formants?</a></li>
  <li><a href="http://microscopy.berkeley.edu/courses/dib/sections/02Images/sampling.html">Nyquist Theorem</a></li>
  <li><a href="http://www.referencedesigner.com/rfcal/cal_04.php">VRMS</a></li>
</ul>

<h2 id="waveform">Waveform</h2>

<p>Speech signals are sound signals, defined as pressure variations travelling through the air.</p>

<p>A speech signal is then represented by a sequence of numbers $ x_n $, which represent the relative air pressure at time-instant n∈ℕ.</p>

<p>This representation is known as pulse code modulation often abbreviated as PCM.</p>

<p>The accuracy of this representation is then specified by two factors;</p>

<ol>
  <li>the sampling frequency (the step in time between $ n $ and $ n+1 $).</li>
  <li>the accuracy and distribution of amplitudes of $ x_n $ .</li>
</ol>

<h3 id="sampling-rate">Sampling Rate</h3>

<p>In DSP Sampling is the reduction of a continuous-time signal to a discrete-time signal.</p>

<p>A common example is the conversion of a sound wave (a continuous signal) to a sequence of samples (a discrete-time signal).</p>

<p>An important aspect of Sampling is the Nyquist Theorem. The Nyquist Theorem states that in order to adequately reproduce a continuous-time signal it should sampled at a rate that is 2X the highest frequency you wish to record.</p>

<p style="text-align: center;"><strong>Nyquist Sampling</strong></p>
<p style="text-align: center;"><strong>$ (f) = d/2 $ </strong></p>

<p style="text-align: center;"><b>Nyquist Sampling (f) = d</b>, where <b>d</b> is the highest frequency you wish to record <b>/ 2</b></p>

<p>Most important information in speech signals are the formants, which reside in the range 300Hz - 3500Hz. This means that the lower limit of the sampling rate will have to be between 7-8kHz.</p>

<h2 id="windowing">Windowing</h2>

<p>A spoken sentence is a sequence of phonemes. Speech signals are therefore time-variant in character. To extract information from a speech signal, the signal must be split into sufficiently short segments, such that heuristically speaking, each segment contains only one phoneme.</p>

<p>Another way to think of this is to extract segments which are short enough that the properties of the speech signal does not have time to change within that segment.</p>

<p>Windowing a common method in signal processing. It is used to split the input signal into temporal segments. When windowing is applied to a signal the borders of the segment are visible as discontinuities.</p>

<p>In other words a windowed segment will have borders that go to zero. Windowing does change the signal however, the change is designed such that its effects on the signal are minimised.</p>

<p>There are two distinct applications of windowing with different requirements;</p>

<ol>
  <li>Analysis</li>
  <li>Processing</li>
</ol>

<p>In analysis the aim is to extract information as accurately as possible. In processing in addition to extracting information we also require the ability to recreate the signal from a sequence of windows.</p>

<p>A standard Hamming window is presented below.</p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="n">np</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="n">plt</span>

<span class="n">window</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">hamming</span><span class="p">(</span><span class="mi">51</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">plot</span><span class="p">(</span><span class="n">window</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">title</span><span class="p">(</span><span class="s">"Hamming Window"</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s">"Ampliture"</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s">"Sample"</span><span class="p">)</span></code></pre></figure>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Text(0.5, 0, 'Sample')
</code></pre></div></div>

<p><img src="https://www.cekose.com/assets/images/notes/speech-rec-notes/output_7_1.png" alt="png" /></p>

<p>For signal analysis we would like the windowed signal to resemble the original signal as much as possible. When choosing a windowing function for analysis, the main criteria to consider is spectral distortion.</p>

<p>For signal processing the most common technique is to use a technique known as overlap-add.</p>

<p><img src="https://www.cekose.com/assets/images/notes/speech-rec-notes/overlap-add.png" alt="png" width="100%" /></p>

<p>In overlap-add, we extract overlapping windows of the signal, apply some processing and reconstruct by windowing a second time and then adding overlapping segments together.</p>

<h2 id="spectrogram-and-short-time-fourier-transform-stft">Spectrogram and Short-time Fourier transform (STFT)</h2>

<p>The Fourier spectrum of a signal reveals the signals constituent frequencies. Revealing the Fourier spectrum of a signal is an intuitive way of examining the signal.</p>

<p>As mentioned earlier speech signals are non-stationary signals. Applying a Fourier transform or visualising the spectrogram of the entire signal will reveal the average of all phonemes in the sentence.</p>

<p>When the goal is to recognise each phoneme separately, we can focus on a single phonome at a time by applying a window to the signal. By windowing and applying a discrete fourier transformation on each window we obtain the Short-time Fourier transform.</p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="c1"># OS library
</span><span class="kn">import</span> <span class="nn">os</span>
<span class="kn">from</span> <span class="nn">os.path</span> <span class="kn">import</span> <span class="n">isdir</span><span class="p">,</span> <span class="n">join</span>
<span class="kn">from</span> <span class="nn">pathlib</span> <span class="kn">import</span> <span class="n">Path</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="n">pd</span>

<span class="c1"># Math
</span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="n">np</span>
<span class="kn">from</span> <span class="nn">scipy.fftpack</span> <span class="kn">import</span> <span class="n">fft</span>
<span class="kn">from</span> <span class="nn">scipy</span> <span class="kn">import</span> <span class="n">signal</span>
<span class="kn">from</span> <span class="nn">scipy.io</span> <span class="kn">import</span> <span class="n">wavfile</span>

<span class="kn">from</span> <span class="nn">sklearn.decomposition</span> <span class="kn">import</span> <span class="n">PCA</span>

<span class="c1"># Visualization
</span><span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="n">plt</span>
<span class="kn">import</span> <span class="nn">IPython.display</span> <span class="k">as</span> <span class="n">ipd</span>


<span class="o">%</span><span class="n">matplotlib</span> <span class="n">inline</span></code></pre></figure>

:ET